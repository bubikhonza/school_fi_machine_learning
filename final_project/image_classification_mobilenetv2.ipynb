{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Honza.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yz5oO4A0mxn6"
      },
      "source": [
        "# Mount google drive for data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s72Y7fGu0XJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHqdYd0qmy28",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7W0D0y2Pver",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2 as cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from sklearn.utils import shuffle\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "import math\n",
        "import h5py\n",
        "\n",
        "#see what GPU is in use\n",
        "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_BZseOouF_H",
        "colab_type": "text"
      },
      "source": [
        "# Load paths to dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scy4rMafPwfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = '/content/drive/My Drive/Colab Notebooks/Data/vehicle/train/train'\n",
        "data = []\n",
        "for category in sorted(os.listdir(root)):\n",
        "    for file in sorted(os.listdir(os.path.join(root, category))):\n",
        "        data.append((category, os.path.join(root, category,  file)))\n",
        "df_train = pd.DataFrame(data, columns=['class', 'file_path'])\n",
        "\n",
        "\n",
        "root2 = '/content/drive/My Drive/Colab Notebooks/Data/vehicle/test/testset'\n",
        "test_data = []\n",
        "for file in sorted(os.listdir(root2)):\n",
        "      test_data.append(os.path.join(root2,  file))\n",
        "df_test = pd.DataFrame(test_data, columns=['file_path'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHbNCnKZuJ1K",
        "colab_type": "text"
      },
      "source": [
        "# Split train data to train and validation (0.2 test size), then convert back to dataframe for generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVc_WZwzYSMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_data = df_train['file_path'].to_numpy()\n",
        "y_data = df_train['class'].to_numpy()\n",
        "\n",
        "#X_data, y_data = shuffle(X_data, y_data)\n",
        "\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_data,\n",
        "                                                                y_data,\n",
        "                                                                test_size=0.2,\n",
        "                                                                random_state=42)\n",
        "\n",
        "train_data = np.array([X_train, y_train])\n",
        "validation_data = np.array([X_validation, y_validation])\n",
        "\n",
        "dataframe_train = pd.DataFrame({'file_path': train_data[0,:], 'class': train_data[1,:]})\n",
        "dataframe_validation = pd.DataFrame({'file_path': validation_data[0,:], 'class': validation_data[1,:]})\n",
        "dataframe_test = df_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO9Kbm8aOKfO",
        "colab_type": "text"
      },
      "source": [
        "# Compute class weights because of unbalanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWbHV9VtNqeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(y_train),\n",
        "                                                 y_train)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "class_weights\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxfV9rnn0pzM",
        "colab_type": "text"
      },
      "source": [
        "# Reducing size of dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC8gJVgj0pWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "dataframe_train = dataframe_train[:1500]\n",
        "dataframe_validation = dataframe_validation[:1500]\n",
        "dataframe_test = dataframe_test[:1500]\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRFs-ht7uYJX",
        "colab_type": "text"
      },
      "source": [
        "# Image data generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27JC6rYls_K8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 8\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe_train,\n",
        "        x_col = 'file_path',\n",
        "        y_col = 'class',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe_validation,\n",
        "        x_col = 'file_path',\n",
        "        y_col = 'class',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe_test,\n",
        "        x_col = 'file_path',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y-2KU7lu7L7",
        "colab_type": "text"
      },
      "source": [
        "# Creating model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkp0nZ33ZDFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = MobileNetV2(include_top = False, input_shape=(224, 224, 3), weights='imagenet')\n",
        "out = base_model.output\n",
        "out = GlobalAveragePooling2D()(out)\n",
        "\n",
        "out = Dense(512, activation=\"relu\")(out)\n",
        "predictions = Dense(17, activation=\"softmax\")(out)\n",
        "\n",
        "model = Model(inputs = base_model.input, outputs = predictions)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HAcLj36u9f_",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZVMAVEPhbdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(train_generator, \n",
        "                steps_per_epoch = math.ceil(len(X_train) / batch_size), \n",
        "                epochs=10,\n",
        "                validation_data=validation_generator,\n",
        "                validation_steps=math.ceil(len(X_validation) / batch_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPZghMBOvVN5",
        "colab_type": "text"
      },
      "source": [
        "# Predicting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx2q-igGvEbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted = model.predict_generator(test_generator, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdNioNdQmGIM",
        "colab_type": "text"
      },
      "source": [
        "# Saving prediction in csv format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XozUS-jQkxI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictedList = list(map(lambda x : np.argmax(x),predicted))\n",
        "classes = list(dict.fromkeys(list(np.array(df_train[\"class\"]))))\n",
        "stringPredictedList = list(map(lambda x : classes[x-1],predictedList))\n",
        "predClasses = pd.DataFrame({'Category': stringPredictedList})\n",
        "ids = pd.DataFrame({'Id':np.arange(len(df_test))})\n",
        "output = pd.concat([ids, predClasses], axis=1)\n",
        "\n",
        "output.to_csv('/content/drive/My Drive/Colab Notebooks/mobile_net_v2_prediction.csv', index = None, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udExS8ErpOoz",
        "colab_type": "text"
      },
      "source": [
        "# Saving model for future use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ORalG4rpIvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/Colab Notebooks/mobilenet_v2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXBJXE5rCqof",
        "colab_type": "text"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8k-sjyr_cab",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<table>\n",
        "<tr>\n",
        "<th>Number of epochs</th>\n",
        "<th>Batch size</th>\n",
        "<th>Optimizer</th>\n",
        "<th>Use of class weights</th>\n",
        "<th>Validation accuracy</th>\n",
        "<th>Dataset size</th>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>3</td>\n",
        "<td>32</td>\n",
        "<td>Adam(0.001)</td>\n",
        "<td>Yes</td>\n",
        "<td>65%</td>\n",
        "<td>15%</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>3</td>\n",
        "<td>64</td>\n",
        "<td>Adam(0.001)</td>\n",
        "<td>Yes</td>\n",
        "<td>69%</td>\n",
        "<td>15%</td>\n",
        "\n",
        "</tr>\n",
        "<tr>\n",
        "<td>4</td>\n",
        "<td>32</td>\n",
        "<td>Adam(0.001)</td>\n",
        "<td>No</td>\n",
        "<td>75%</td>\n",
        "<td>15%</td>\n",
        "\n",
        "</tr>\n",
        "<tr>\n",
        "<td>4</td>\n",
        "<td>64</td>\n",
        "<td>Adam(0.001)</td>\n",
        "<td>No</td>\n",
        "<td>76%</td>\n",
        "<td>15%</td>\n",
        "\n",
        "</tr>\n",
        "<tr>\n",
        "<td>4</td>\n",
        "<td>8</td>\n",
        "<td>Adam(0.001)</td>\n",
        "<td>No</td>\n",
        "<td>77%</td>\n",
        "<td>15%</td>\n",
        "\n",
        "</tr>\n",
        "<tr>\n",
        "<td>4</td>\n",
        "<td>32</td>\n",
        "<td>Adam(0.0001)</td>\n",
        "<td>No</td>\n",
        "<td>74%</td>\n",
        "<td>15%</td>\n",
        "\n",
        "</tr>\n",
        "<tr>\n",
        "<td>10</td>\n",
        "<td>8</td>\n",
        "<td>Adam(0.0005)</td>\n",
        "<td>No</td>\n",
        "<td>81%</td>\n",
        "<td>100%</td>\n",
        "\n",
        "</tr>\n",
        "\n",
        "\n",
        "</table>\n",
        "\n"
      ]
    }
  ]
}